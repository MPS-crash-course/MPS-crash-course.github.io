
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>3. Matrix Product States &#8212; MPS Crash Course</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/week1/mps';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="4. Canonical Form and Truncation" href="../week2/canonical.html" />
    <link rel="prev" title="2. The Heisenberg Antiferromagnet" href="problem.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../home.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.jpg" class="logo__image only-light" alt="MPS Crash Course - Home"/>
    <img src="../../_static/logo.jpg" class="logo__image only-dark pst-js-only" alt="MPS Crash Course - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../home.html">
                    MPS Crash Course
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 1</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="problem.html">2. The Heisenberg Antiferromagnet</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">3. Matrix Product States</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../week2/canonical.html">4. Canonical Form and Truncation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week2/tebd.html">5. Time Evolving Block Decimation (TEBD)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../week3/mpo.html">6. Matrix Product Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week3/dmrg.html">7. Density Matrix Renormalization Group (DMRG)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../week4/dsf.html">8. Bringing It All Together</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/MPS-crash-course/MPS-crash-course.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/MPS-crash-course/MPS-crash-course.github.io/issues/new?title=Issue%20on%20page%20%2Fcontent/week1/mps.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/week1/mps.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Matrix Product States</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantum-states-of-many-spins">3.1. Quantum states of many spins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.2. Matrix Product States</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-network-diagrams">3.3. Tensor network diagrams</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#numpy-tensordot-and-transpose">3.4. Numpy tensordot and transpose</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mps-from-a-state-vector">3.5. MPS from a state vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mps-to-vector">3.6. MPS to vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#product-states">3.7. Product states</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">3.8. Summary</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="matrix-product-states">
<h1><span class="section-number">3. </span>Matrix Product States<a class="headerlink" href="#matrix-product-states" title="Link to this heading">#</a></h1>
<p>Matrix product states are an efficient way of expressing and/or approximating many-body quantum states. They are particularly useful for studying one-dimensional quantum systems, but have applications in higher dimensions, and also for studying classical systems. In this course we will be focussing on the one-dimensional Heisenberg model, which is a model of interacting quantum spins.</p>
<section id="quantum-states-of-many-spins">
<h2><span class="section-number">3.1. </span>Quantum states of many spins<a class="headerlink" href="#quantum-states-of-many-spins" title="Link to this heading">#</a></h2>
<p>A spin-1/2 degree of freedom is simply a two level quantum system. These two levels may correspond to the two possible spin states of a fundamental particle, such as an electron, or they could be effective degrees of freedom of a more complex system.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>From now on we will use the terms “spin” and “spin-1/2 particle” interchangeably.</p>
</div>
<p>We typically label the two states as <span class="math notranslate nohighlight">\(|\uparrow\rangle\)</span> and <span class="math notranslate nohighlight">\(|\downarrow\rangle\)</span>, or equivalently as <span class="math notranslate nohighlight">\(|0\rangle\)</span> and <span class="math notranslate nohighlight">\(|1\rangle\)</span>. The most general state of a single spin can be written as a superposition of these two states, that is,</p>
<div class="math notranslate nohighlight">
\[
|\psi\rangle = \psi_0 |0\rangle + \psi_1 |1\rangle,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\psi_0\)</span> and <span class="math notranslate nohighlight">\(\psi_1\)</span> are complex numbers that satisfy <span class="math notranslate nohighlight">\(|\psi_0|^2 + |\psi_1|^2 = 1\)</span>. This is because the state <span class="math notranslate nohighlight">\(|\psi\rangle\)</span> must be normalized, that is, <span class="math notranslate nohighlight">\(\langle \psi | \psi \rangle = 1\)</span>. These complex number <span class="math notranslate nohighlight">\(\psi_i\)</span> are known as the <em>probability amplitudes</em> for the state <span class="math notranslate nohighlight">\(|\psi\rangle\)</span>. If we had two spins, then the most general state would be</p>
<div class="math notranslate nohighlight">
\[
|\psi\rangle = \psi_{00} |00\rangle + \psi_{01} |01\rangle + \psi_{10} |10\rangle + \psi_{11} |11\rangle,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\psi_{ij}\)</span> satisfy the normalization condition <span class="math notranslate nohighlight">\(\sum_{i,j} |\psi_{ij}|^2 = 1\)</span>. Here we have introduced the shorthand notation <span class="math notranslate nohighlight">\(|ij\rangle = |i\rangle \otimes |j\rangle\)</span> for the tensor product of the single spin states. Continuing in this fashion, the state of <span class="math notranslate nohighlight">\(N\)</span> particles is given by</p>
<div class="math notranslate nohighlight" id="equation-eq-generalstate">
<span class="eqno">(3.1)<a class="headerlink" href="#equation-eq-generalstate" title="Link to this equation">#</a></span>\[
|\psi\rangle = \sum_{i_1, i_2, \ldots, i_N} \psi_{i_1 i_2 \ldots i_N} |i_1 i_2 \ldots i_N\rangle,
\]</div>
<p>where the sum is over all possible combinations of <span class="math notranslate nohighlight">\(i_1, i_2, \ldots, i_N \in \{\uparrow, \downarrow\}\)</span>. The number of probability amplitudes required to specify the state of <span class="math notranslate nohighlight">\(N\)</span> particles grows exponentially with <span class="math notranslate nohighlight">\(N\)</span>, which is known as the curse of dimensionality. In exact numerical calculations, we typically store the complete list of probability amplitudes as a vector. For <span class="math notranslate nohighlight">\(N\)</span> spins particles, this vector has <span class="math notranslate nohighlight">\(2^N\)</span> complex numbers, which is becomes very quickly infeasible for large <span class="math notranslate nohighlight">\(N\)</span>.</p>
</section>
<section id="id1">
<h2><span class="section-number">3.2. </span>Matrix Product States<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Matrix product states (MPS) provide a way of representing the state of a many-body quantum system in a more efficient way. The key idea is to write the state as a product of matrices, where each matrix corresponds to a single spin. The state of a single spin is then given by the product of these matrices. More explicitly, the probability amplitudes in <a class="reference internal" href="#equation-eq-generalstate">(3.1)</a> can be rewritten in terms of a product of matrices <span class="math notranslate nohighlight">\(M^{[n] i_n}\)</span> as</p>
<div class="math notranslate nohighlight">
\[
\psi_{i_1 i_2 \ldots i_N} = M^{[1] i_1} M^{[2] i_2} \cdots M^{[N] i_N},
\]</div>
<p>where each <span class="math notranslate nohighlight">\(M^{[n] i_n}\)</span> is a <span class="math notranslate nohighlight">\(\chi_n \times \chi_{n+1}\)</span> matrix. We include the <span class="math notranslate nohighlight">\([n]\)</span> superscript to indicate that the matrix matrix is associated with the <span class="math notranslate nohighlight">\(n^{\text{th}}\)</span> spin. The superscript <span class="math notranslate nohighlight">\(i_n\)</span> indicates the state of the <span class="math notranslate nohighlight">\(n^{\text{th}}\)</span> spin. That the probability amplitude (and hence the state) can be written in this way is perhaps not immediately obvious, but we will soon discuss how to find the matrices <span class="math notranslate nohighlight">\(M^{[n] i_n}\)</span>, and convert from a state vector to a MPS.</p>
<p>Instead of dealing with an MPS as a product of matrices, it is instead more useful to expose the matrix indices explicitly. That is <span class="math notranslate nohighlight">\([M^{[n] i_n}]_{\alpha_n, \alpha_{n+1}} = M^{[n] i_n}_{\alpha_n, \alpha_{n+1}}\)</span> where <span class="math notranslate nohighlight">\(\alpha_n\)</span> and <span class="math notranslate nohighlight">\(\alpha_{n+1}\)</span> are the indices of the matrix. The state of the system can then be written as</p>
<div class="math notranslate nohighlight" id="equation-eq-mps">
<span class="eqno">(3.2)<a class="headerlink" href="#equation-eq-mps" title="Link to this equation">#</a></span>\[
\psi_{i_1 i_2 \ldots i_N} = \sum_{\alpha_1, \alpha_2, \ldots, \alpha_N} M^{[1]i_1}_{\alpha_0,\alpha_1} M^{[2]i_2}_{\alpha_2, \alpha_3}M^{[3]i_3}_{\alpha_3, \alpha_4} \cdots M^{[N]i_N}_{\alpha_{N},\alpha_{N+1}}.
\]</div>
<p>It is then more useful to treat the matrices <span class="math notranslate nohighlight">\(M^{[n]i_n}_{\alpha_n,\alpha_{n+1}}\)</span>, as rank-3 tensors, with indices <span class="math notranslate nohighlight">\(i_n, \alpha_n, \alpha_n\)</span>. Since these expressions can become cumbersome, we will also introduce a graphical notation to represent these tensors. This graphical notation is known as the tensor network diagram, and is a powerful tool for understanding and manipulating tensor networks. Let us introduce this notation before returning to this expression for the matrix product state.</p>
<div class="admonition-code-mps-class admonition">
<p class="admonition-title">Code: MPS Class</p>
<p>Since we know what the MPS representation of a state is, i.e., a collection of rank-3 tensors, one for each site, we can write a class that represents an MPS. We will start this class as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## file: src/mps.py</span>

<span class="k">class</span> <span class="nc">MPS</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Matrix Product State class for 1D quantum systems of spin-1/2 particles.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    L : Int </span>
<span class="sd">        number of sites</span>
<span class="sd">    tensors : list of np.Array[ndim=3]</span>
<span class="sd">        list of tensors. Indices are (left, physical, right)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">tensors</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">L</span> <span class="o">=</span> <span class="n">L</span>  <span class="c1"># number of sites</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensors</span> <span class="o">=</span> <span class="n">tensors</span>  <span class="c1"># list of tensors. Indices are (left, physical, right)</span>
        

    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MPS</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">,</span> <span class="p">[</span><span class="n">tensor</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensors</span><span class="p">])</span>
</pre></div>
</div>
<p>The class consists of two attributes: <code class="docutils literal notranslate"><span class="pre">L</span></code> which is the number of sites in the system, and <code class="docutils literal notranslate"><span class="pre">tensors</span></code> which is a list of rank-3 tensors. These tensors are numpy arrays. The <code class="docutils literal notranslate"><span class="pre">copy</span></code> method is a useful method to have, as we will often want to make a copy of an MPS.</p>
</div>
</section>
<section id="tensor-network-diagrams">
<h2><span class="section-number">3.3. </span>Tensor network diagrams<a class="headerlink" href="#tensor-network-diagrams" title="Link to this heading">#</a></h2>
<p>Rather than constantly writing out tensors, their many indices, and the sums over these indices, we can introduce a simple diagramatic approach to represent these expressions, as shown in <a class="reference internal" href="#fig-simple-diagrams"><span class="std std-numref">Fig. 3.1</span></a>. In this notation, the tensor is represented by a shape (in this case a circle), and the outcoming lines (referred to as legs) represent the indices of the tensor. The number of legs is equal to the rank of the tensor. For example, the vector <span class="math notranslate nohighlight">\(v_i\)</span> is represented by a circle with a single leg, the matrix <span class="math notranslate nohighlight">\(M_{ij}\)</span> by two legs, and the rank-3 tensor <span class="math notranslate nohighlight">\(A_{ijk}\)</span> by three legs.</p>
<figure class="align-center" id="fig-simple-diagrams">
<a class="reference internal image-reference" href="../../_images/simple_tensor_diagrams.jpeg"><img alt="../../_images/simple_tensor_diagrams.jpeg" src="../../_images/simple_tensor_diagrams.jpeg" style="width: 50%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.1 </span><span class="caption-text">Some simple objects as tensor network diagrams. (Left) A vector <span class="math notranslate nohighlight">\(v_i\)</span>. (Middle) A matrix <span class="math notranslate nohighlight">\(M_{ij}\)</span>. (Right) A rank-3 tensor <span class="math notranslate nohighlight">\(A_{ijk}\)</span>.</span><a class="headerlink" href="#fig-simple-diagrams" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>We can also represent a type of product between these tensors, which we call <em>contraction</em>. This is done diagramatically by connecting the legs of the two tensors. This corresponds to taking the product of the tensor elements and summing over the repeated index. For example, in <a class="reference internal" href="#fig-contraction"><span class="std std-numref">Fig. 3.2</span></a> we show the contraction of a matrix acting on a vector, and the contraction of two matrices, both in terms of matrix elements and as tensor network diagrams.</p>
<figure class="align-center" id="fig-contraction">
<a class="reference internal image-reference" href="../../_images/matrix_product_diagrams.jpeg"><img alt="../../_images/matrix_product_diagrams.jpeg" src="../../_images/matrix_product_diagrams.jpeg" style="width: 80%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.2 </span><span class="caption-text">(Left) A matrix acting on a vector written as a sum over indices and drawn as a tensor network diagram. (Right) Similar for the product of two matrices.</span><a class="headerlink" href="#fig-contraction" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>These kind of tensor contractions are the core part of the code we will write to manipulate MPS.</p>
<p>We are then able to draw our MPS from Eq.<a class="reference internal" href="#equation-eq-mps">(3.2)</a> as a tensor network diagram, as shown in <a class="reference internal" href="#fig-mps-diagram"><span class="std std-numref">Fig. 3.3</span></a>. It consists of a line of rank-3 tensors. The legs that are not contracted are referred to as physical legs, and those that are contracted are virtual legs. The physical legs correspond to the indices of the tensor that are associated with the physical degrees of freedom of the system, in this case the spin states. The virtual legs correspond to the indices that are summed over in the contraction.</p>
<figure class="align-center" id="fig-mps-diagram">
<a class="reference internal image-reference" href="../../_images/mps_diagram.jpeg"><img alt="../../_images/mps_diagram.jpeg" src="../../_images/mps_diagram.jpeg" style="width: 50%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.3 </span><span class="caption-text">A matrix product state on 5 sites as a tensor network diagram. The physical legs are the dangling vertical lines that are labelled, and the virtual legs are the horizontal lines. The end tensors are shown with a dashed line to indicate that there free indices are dimension 1. This allows us to write each tensor as a rank-3 numpy array, simplifying our code. Strictly speaking, the results of the contraction of this diagram is a <span class="math notranslate nohighlight">\(1\times 1\)</span> matrix (which is equivalent to a scalar).</span><a class="headerlink" href="#fig-mps-diagram" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="numpy-tensordot-and-transpose">
<span id="tensordot"></span><h2><span class="section-number">3.4. </span>Numpy tensordot and transpose<a class="headerlink" href="#numpy-tensordot-and-transpose" title="Link to this heading">#</a></h2>
<p>In our MPS class, the tensors are given by rank-3 numpy arrays. In order to perform the contraction and keep track of the indices, we will use the numpy <code class="docutils literal notranslate"><span class="pre">tensordot</span></code> and <code class="docutils literal notranslate"><span class="pre">transpose</span></code> functions. The <code class="docutils literal notranslate"><span class="pre">tensordot</span></code> function is used to contract two tensors along specified axes. The <code class="docutils literal notranslate"><span class="pre">transpose</span></code> function is used to permute the axes of a tensor.</p>
<p>It is easiest to work through examples to understand how these functions work. Let use consider the examples in <a class="reference internal" href="#fig-contraction"><span class="std std-numref">Fig. 3.2</span></a>. Starting with the matrix acting on a vector, we can write the contraction as</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the tensors</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># vector</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>  <span class="c1"># matrix</span>

<span class="c1"># Contract the matrix with the vector</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1"># check that the result matches</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">M</span> <span class="o">@</span> <span class="n">v</span><span class="p">),</span> <span class="s2">&quot;matrix-vector multiplication failed!&quot;</span> 

</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">tensordot</span></code> function takes three arguments. The first two are the arrays that we are contracting. The third argument specifies the axes that we are contracting over (specified as a tuple of lists). In this case we are contracting over the 1st of the matrix and 0th of the vector.</p>
<p>For the product of two matrices, let us do the contraction in two different ways by putting the matrices into <code class="docutils literal notranslate"><span class="pre">tensordot</span></code> in different orders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># Define the tensors</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>  <span class="c1"># matrix</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>  <span class="c1"># matrix</span>

<span class="c1"># Contract the matrices</span>
<span class="n">result1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1"># Contract the matrices in the opposite order</span>
<span class="n">result2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">result2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">result2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>  <span class="c1"># transpose the result to match the order of the indices</span>

<span class="c1"># check that the result matches</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">result1</span><span class="p">,</span> <span class="n">A</span> <span class="o">@</span> <span class="n">B</span><span class="p">),</span> <span class="s2">&quot;matrix-matrix method 1 failed!&quot;</span>  
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">result2</span><span class="p">,</span> <span class="n">A</span> <span class="o">@</span> <span class="n">B</span><span class="p">),</span> <span class="s2">&quot;matrix-matrix method 2 failed!&quot;</span> 

</pre></div>
</div>
<p>When contracting using <code class="docutils literal notranslate"><span class="pre">tensordot</span></code>, order of indices will be a list of those remaining from the first array, followed by the remaining indices from the second. The two ways of contracting are equivalent to the following equations</p>
<div class="math notranslate nohighlight">
\[
C_{ij} = \sum_k A_{ik} B_{kj}, \quad \text{and} \quad
\widetilde{C}_{ji} = \sum_k B_{kj} A_{ik}.
\]</div>
<p>In the second case we need to transpose the result to match the order of the indices. The <code class="docutils literal notranslate"><span class="pre">transpose</span></code> function allows us to perform a generalised transpose of tensors. The arguments are the array to transpose, followed by the new order of the axes.</p>
<p>Let us consider a final example using rank-3 tensors, which will be very similar to the type of contractions we will be performing in our MPS code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="c1"># Define the tensors</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>  <span class="c1"># (left, physical, right)</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>  <span class="c1"># (left, physical, right)</span>

<span class="c1"># Contract the tensors along the physical indices</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># (l1,p,r1) * (l2,p,r2) -&gt; (l1,r1,l2,r2)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>  <span class="c1"># (l1,r1,l2,r2) -&gt; (l1,l2,r1,r2)</span>

</pre></div>
</div>
<p>Here we are computing the object</p>
<div class="math notranslate nohighlight">
\[
\Theta_{ijkl} = \sum_p A_{i p k} B_{j p l},
\]</div>
<p>which we also show diagramatically in <a class="reference internal" href="#fig-theta-example"><span class="std std-numref">Fig. 3.4</span></a>. For more complex contractions it is good practice to add comments to your code keeping track of the indices. Here at the end we have transposed the result so that those on the left in <a class="reference internal" href="#fig-theta-example"><span class="std std-numref">Fig. 3.4</span></a> come before those on the right.</p>
<figure class="align-center" id="fig-theta-example">
<a class="reference internal image-reference" href="../../_images/theta_example.jpeg"><img alt="../../_images/theta_example.jpeg" src="../../_images/theta_example.jpeg" style="width: 60%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.4 </span><span class="caption-text">The contraction of two rank-3 tensors <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> along the physical indices. The result is a rank-4 tensor <span class="math notranslate nohighlight">\(\Theta\)</span>. I have included coloured numbers showing the order of the indices as stored in the numpy arrays. To arrive at the final ordering for <span class="math notranslate nohighlight">\(\Theta\)</span> we need to transpose the result.</span><a class="headerlink" href="#fig-theta-example" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition-exercise-contracting-tensors admonition">
<p class="admonition-title">Exercise: Contracting tensors</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensordot</span></code> and <code class="docutils literal notranslate"><span class="pre">transpose</span></code> functions can be quite confusing if you haven’t dealt with tensors before, but are the main functions we will need throughout this course. I would therefore encourage you to play around with these to get a better feeling of how they work. The easiest way to do this is to work with matrices, where you can easily check the reaults by hand, or by printing the arrays.</p>
<p>Try the following exercises (all using square matrices complex matrices <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>):</p>
<ol class="arabic simple">
<li><p>Compute <span class="math notranslate nohighlight">\(\text{Tr}(A B) = \sum_{ij} A_{ij} B_{ji}\)</span> with <span class="math notranslate nohighlight">\(A\)</span> in the first position and <span class="math notranslate nohighlight">\(B\)</span> in the second.</p></li>
<li><p>Same as 1. but with the matrices appearing in the opposite order in <code class="docutils literal notranslate"><span class="pre">tensordot</span></code>.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(A^\dagger B\)</span> where <span class="math notranslate nohighlight">\(A^\dagger\)</span> is the complex conjugate transpose of <span class="math notranslate nohighlight">\(A\)</span>. Compute this with <span class="math notranslate nohighlight">\(A^\dagger\)</span> in the first position and <span class="math notranslate nohighlight">\(B\)</span> in the second.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(A^\dagger B\)</span>, but with <span class="math notranslate nohighlight">\(A^*\)</span> (complex conjugate) in the second position and <span class="math notranslate nohighlight">\(B\)</span> in the first.</p></li>
</ol>
<p>I would recommend adding a file <code class="docutils literal notranslate"><span class="pre">tensordot.py</span></code> to your <code class="docutils literal notranslate"><span class="pre">exercises</span></code> directory and working through these exercises there. Make sure to add the line <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">fix_pathing</span> <span class="pre">import</span> <span class="pre">root_dir</span></code>. You can then import your MPS class using <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">src.mps</span> <span class="pre">import</span> <span class="pre">MPS</span></code>.</p>
</div>
</section>
<section id="mps-from-a-state-vector">
<h2><span class="section-number">3.5. </span>MPS from a state vector<a class="headerlink" href="#mps-from-a-state-vector" title="Link to this heading">#</a></h2>
<p>Now we have the diagramatic notation and the corresponding python functions at our disposal, let us return to the MPS representation. In particular, we want to explicitly relate the matrices in the MPS to the vector of probability amplitudes. The MPS can be drawn as the tensor network diagram shown in ???. Note the dashed virtual indices that are dangling on the end tensors. These are 1 dimensional indices and are simply included to make our code simpler (we only have to treat one shape of array). The result of this diagram when we specify all the physical indices is then not technically a number, but a <span class="math notranslate nohighlight">\(1\times 1\)</span> matrix.</p>
<p>We will now show how to convert a state vector into this MPS form. This will involve the use of numpy <code class="docutils literal notranslate"><span class="pre">reshape</span></code>, as well as singular value decomposition (SVD).</p>
<p>Let us start by thinking what we mean by treating <span class="math notranslate nohighlight">\(\psi_{i_1, i_2, \ldots, i_N}\)</span> as a vector. One way to think of this is that <span class="math notranslate nohighlight">\((i_1, i_2, \ldots, i_N)\)</span> is a binary representation of the index of the vector. That is the probability amplitude corresponding to <span class="math notranslate nohighlight">\(|000\rangle\)</span> is in the 0th position, <span class="math notranslate nohighlight">\(|001\rangle\)</span> in the 1st position, and so on. Instead, we will no choose to separate out the first spin, and instead write the state as the matrix <span class="math notranslate nohighlight">\(\psi_{(i_1),(i_2 \ldots i_N)}\)</span>. That is, <span class="math notranslate nohighlight">\(|000\rangle\)</span> corresponds to <span class="math notranslate nohighlight">\(\psi_{0, 0}\)</span>, <span class="math notranslate nohighlight">\(|001\rangle\)</span> to <span class="math notranslate nohighlight">\(\psi_{0, 1}\)</span>, and <span class="math notranslate nohighlight">\(|100\rangle\)</span> to <span class="math notranslate nohighlight">\(\psi_{1,0}\)</span>, and so on. This is a simple reshaping of the vector into a matrix, and can be done using <code class="docutils literal notranslate"><span class="pre">reshape</span></code> as follows in python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">psi</span>  <span class="c1"># the vector of probability amplitudes</span>

<span class="c1"># Reshape the vector into a matrix</span>
<span class="n">psi</span> <span class="o">=</span> <span class="n">psi</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

</pre></div>
</div>
<p>We specify that the matrix should have 2 rows, and then let python figure out how many columns are needed. Diagramatically this is shown in the first step of <a class="reference internal" href="#fig-split-first-site"><span class="std std-numref">Fig. 3.5</span></a>. We can then decompose this matrix using Singular Value Decomposition (SVD). The SVD of a matrix <span class="math notranslate nohighlight">\(A\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[
A = U S V^\dagger,
\]</div>
<p>where <span class="math notranslate nohighlight">\(U\)</span> and <span class="math notranslate nohighlight">\(V\)</span> are unitary matrices, and <span class="math notranslate nohighlight">\(S\)</span> is a diagonal matrix. The diagonal elements of <span class="math notranslate nohighlight">\(S\)</span>, typically labelled <span class="math notranslate nohighlight">\(\lambda_i\)</span>, are the singular values, which are non-negative, and are ordered from largest to smallest. In this context, the singular value decomposition is the same as the Schmidt decomposition, and the singular values are the Schmidt coefficients. Since the state we start from is pure and normalized, we have that <span class="math notranslate nohighlight">\(\sum_i \lambda_i^2 = 1\)</span>. These Schmidt values have an important physical meaning, which we will return to when we discuss truncation of the MPS next week. The SVD is shown diagramatically in <a class="reference internal" href="#fig-split-first-site"><span class="std std-numref">Fig. 3.5</span></a>, and can be computed in python as using <code class="docutils literal notranslate"><span class="pre">numpy.linalg</span></code> (or <code class="docutils literal notranslate"><span class="pre">scipy.linalg</span></code>) by</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">la</span>

<span class="n">U</span><span class="p">,</span> <span class="n">S</span><span class="p">,</span> <span class="n">Vdg</span> <span class="o">=</span> <span class="n">la</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
</pre></div>
</div>
<p>where we specify <code class="docutils literal notranslate"><span class="pre">full_matrices=False</span></code> since we are working with a rectangular matrix. If we have a <span class="math notranslate nohighlight">\(m \times n\)</span> matrix, then this reduced SVD returns <span class="math notranslate nohighlight">\(U\)</span> as <span class="math notranslate nohighlight">\(m \times k\)</span>, <span class="math notranslate nohighlight">\(S\)</span> a length <span class="math notranslate nohighlight">\(k\)</span> vector, and <span class="math notranslate nohighlight">\(V^\dagger\)</span> as <span class="math notranslate nohighlight">\(k \times n\)</span> matrix, where <span class="math notranslate nohighlight">\(k = \min(m,n)\)</span>.</p>
<figure class="align-center" id="fig-split-first-site">
<a class="reference internal image-reference" href="../../_images/split_first_site.jpeg"><img alt="../../_images/split_first_site.jpeg" src="../../_images/split_first_site.jpeg" style="width: 60%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.5 </span><span class="caption-text">The first step of using Singular Value Decomposition to split a vector into an MPS. The vector is first reshaped into a matrix, and then decomposed into <span class="math notranslate nohighlight">\(U\)</span>, <span class="math notranslate nohighlight">\(S\)</span>, and <span class="math notranslate nohighlight">\(V^\dagger\)</span>. The matrix <span class="math notranslate nohighlight">\(U\)</span> is reshapes into a rank-3 tensor and is the first tensor of the MPS. The matrices <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(V^\dagger\)</span> are combined to form the matrix <span class="math notranslate nohighlight">\(R\)</span>, which goes to the next step.</span><a class="headerlink" href="#fig-split-first-site" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The matrix <span class="math notranslate nohighlight">\(U\)</span> is then the first tensor in our MPS, i.e. <span class="math notranslate nohighlight">\(M^{[1]}\)</span>. For practical reasons, we want this tensor to be rank-3, so that we can deal with the tensors from each site in the same way. Therefore, we reshape this tensor again using <code class="docutils literal notranslate"><span class="pre">np.reshape(U,</span> <span class="pre">(1,</span> <span class="pre">2,</span> <span class="pre">-1))</span></code>. The first index has dimension 1, and we represent this using a dashed line, as shown in <a class="reference internal" href="#fig-split-first-site"><span class="std std-numref">Fig. 3.5</span></a>. The second index has dimension 2 and this is the physical index, and the third index connects to the rest of the sites and is the virtual index. For the first site it will also be dimension 2. We then combine <span class="math notranslate nohighlight">\(S\)</span> and <span class="math notranslate nohighlight">\(V^\dagger\)</span> to form a tensor which we call <span class="math notranslate nohighlight">\(R\)</span>.</p>
<figure class="align-center" id="fig-split-general-site">
<a class="reference internal image-reference" href="../../_images/split_general_site.jpeg"><img alt="../../_images/split_general_site.jpeg" src="../../_images/split_general_site.jpeg" style="width: 70%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.6 </span><span class="caption-text">The general step for converting a state vector into an MPS. The tensor <span class="math notranslate nohighlight">\(R\)</span> is reshaped and then decomposed using SVD. The resulting <span class="math notranslate nohighlight">\(U\)</span> is reshaped into a rank-3 tensor, and the <span class="math notranslate nohighlight">\(S\)</span> is multiplied into <span class="math notranslate nohighlight">\(V^\dagger\)</span> to form the next <span class="math notranslate nohighlight">\(R\)</span>.</span><a class="headerlink" href="#fig-split-general-site" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>We then repeat this process down the chain, as shown in <a class="reference internal" href="#fig-split-general-site"><span class="std std-numref">Fig. 3.6</span></a>. We start by taking the tensor <span class="math notranslate nohighlight">\(R\)</span>, which should be a <span class="math notranslate nohighlight">\(\chi \times 2^m\)</span> matrix, where <span class="math notranslate nohighlight">\(\chi\)</span> is the number of Schmidt values from the previous step. We reshape this into a <span class="math notranslate nohighlight">\(2\chi \times 2^{m-1}\)</span> tensor, and then perform the SVD. Effectively, this groups the left virtual index with the next physical site, and then the other dimension corresponds to the rest of the sites. We then perform the SVD, reshape <span class="math notranslate nohighlight">\(U\)</span> to be <span class="math notranslate nohighlight">\(\chi \times 2 \times 2^{m-1}\)</span>, and multiply <span class="math notranslate nohighlight">\(S\)</span> into <span class="math notranslate nohighlight">\(V^\dagger\)</span> to form the next <span class="math notranslate nohighlight">\(R\)</span>. We repeat this process until we have tensors for all sites, as shown in <a class="reference internal" href="#fig-state-to-mps"><span class="std std-numref">Fig. 3.7</span></a>. When we get to the end of the chain, we reshape <span class="math notranslate nohighlight">\(R\)</span> into a rank-3 tensor, and this is the final tensor in the MPS.</p>
<figure class="align-center" id="fig-state-to-mps">
<a class="reference internal image-reference" href="../../_images/state_to_mps.jpeg"><img alt="../../_images/state_to_mps.jpeg" src="../../_images/state_to_mps.jpeg" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.7 </span><span class="caption-text">Tensor network diagrams for the process of converting a state vector to an MPS. The tensors of the MPS are split off from the vector by repeatedly reshaping and performing singular value decomposition. The final MPS is then a chain of tensors with bond dimension growing exponentially towards the centre of the chain.</span><a class="headerlink" href="#fig-state-to-mps" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>This process of successively splitting the vector into tensors using SVD provides a proof-by-construction, that our MPS representation is equivalent to the original state vector. However, this process leads to a chain of tensor where the dimension of the virtual indices, known as the <em>bond dimension</em>, grows exponentially towards the centre of the chain. Hence, we have not actually gained anything. In practice, the power of MPS comes from truncating these tensors, restricting the bond dimension, and hence providing an approximation to the state vector. We will discuss this truncation process in more detail in the coming weeks.</p>
<div class="admonition-code-extend-the-mps-class admonition">
<p class="admonition-title">Code: Extend the MPS Class</p>
<p>Since we have an algorithm to convert a state vector to an MPS, let us extend our MPS class to include this method. You should attempt this yourself, by following the structure below. A model solution can be found in the GitHub repository.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## file: src/mps.py</span>

<span class="k">class</span> <span class="nc">MPS</span><span class="p">:</span>
    
    <span class="c1">## PREVIOUS CODE EXCLUDED ##</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">fromVector</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">vector</span><span class="p">):</span>

        <span class="n">L</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">vector</span><span class="o">.</span><span class="n">size</span><span class="p">))</span>  <span class="c1"># number of sites</span>

        <span class="c1">## YOUR CODE HERE ##</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">tensors</span><span class="p">)</span>
</pre></div>
</div>
<p>We can add this as a <code class="docutils literal notranslate"><span class="pre">classmethod</span></code> to our MPS class. If you are not familiar with class methods, they are methods associated with the class type itself, not with an instance of the class. We would use this as follows: <code class="docutils literal notranslate"><span class="pre">psi</span> <span class="pre">=</span> <span class="pre">MPS.fromVector(vector)</span></code>. Here we are calling the method <code class="docutils literal notranslate"><span class="pre">fromVector</span></code>, on the abstract class type <code class="docutils literal notranslate"><span class="pre">MPS</span></code>, and it will return an instance of the class, which we call <code class="docutils literal notranslate"><span class="pre">psi</span></code>. Just like regular methods require <code class="docutils literal notranslate"><span class="pre">self</span></code> as the first argument, class methods require <code class="docutils literal notranslate"><span class="pre">cls</span></code>.</p>
</div>
</section>
<section id="mps-to-vector">
<h2><span class="section-number">3.6. </span>MPS to vector<a class="headerlink" href="#mps-to-vector" title="Link to this heading">#</a></h2>
<p>We can also convert back from an MPS to a state vector. This is a simple process of contracting the tensors in the MPS, and then reshaping the result into a vector. We can do this by contracting the tensors from left to right, as shown in <a class="reference internal" href="#fig-mps-to-state"><span class="std std-numref">Fig. 3.8</span></a>. We start by contracting the first two tensors, then contract the result with the next tensor. Each time, we reshape the resulting rank-4 tensor into a rank-3 tensor by grouping the physical legs. We continue this process until we have contracted all the tensors, and then take the <span class="math notranslate nohighlight">\((0,0)\)</span> element of the resulting <span class="math notranslate nohighlight">\(1\times 1\)</span> matrix.</p>
<figure class="align-center" id="fig-mps-to-state">
<a class="reference internal image-reference" href="../../_images/mps_to_state.jpeg"><img alt="../../_images/mps_to_state.jpeg" src="../../_images/mps_to_state.jpeg" style="width: 100%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3.8 </span><span class="caption-text">Tensor network diagrams for the process of converting an MPS to a state vector. The tensors of the MPS are contracted from left to right, and the result reshaped into a vector.</span><a class="headerlink" href="#fig-mps-to-state" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition-code-extend-the-mps-class admonition">
<p class="admonition-title">Code: Extend the MPS Class</p>
<p>Let us also add the method to convert an MPS to a state vector.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## file: src/mps.py</span>

<span class="k">class</span> <span class="nc">MPS</span><span class="p">:</span>
    
    <span class="c1">## PREVIOUS CODE EXCLUDED ##</span>

    <span class="k">def</span> <span class="nf">toVector</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1">## YOUR CODE HERE ##</span>

        <span class="k">return</span> <span class="n">vector</span>
</pre></div>
</div>
<p>We add this as a regular method to the MPS class. We can then call this method on an instance of the class, e.g. <code class="docutils literal notranslate"><span class="pre">vector</span> <span class="pre">=</span> <span class="pre">psi.toVector()</span></code>.</p>
</div>
</section>
<section id="product-states">
<h2><span class="section-number">3.7. </span>Product states<a class="headerlink" href="#product-states" title="Link to this heading">#</a></h2>
<p>As we mentioned above, creating an MPS from a state vector is not very useful (except for testing our code, as we will below). The power of MPS comes from representing quantum states with a low, finite bond dimension. A simple example of states that can be exactly represented with minimal bond dimension are product states. We will use these both as a starting point for time evolution to simulate a quantum quench (week 2), but also as a starting point for the DMRG algorithm to find the ground state of the Heisenberg model (week 3).</p>
<p>A product state is a state which factorizes into a product of single site states. That is, the state of <span class="math notranslate nohighlight">\(N\)</span> spins is given by</p>
<div class="math notranslate nohighlight">
\[
|\psi\rangle = |\psi_1\rangle \otimes |\psi_2\rangle \otimes \cdots \otimes |\psi_N\rangle,
\]</div>
<p>where <span class="math notranslate nohighlight">\(|\psi_i\rangle\)</span> is the state of the <span class="math notranslate nohighlight">\(i^{\text{th}}\)</span> spin. The probability amplitudes for the many-body state <span class="math notranslate nohighlight">\(\psi_{i_1 i_2 \ldots i_N}\)</span>, can then be written as a product of the probability amplitudes for the single site states, i.e.,</p>
<div class="math notranslate nohighlight">
\[
\psi_{i_1 i_2 \ldots i_N} = \psi_{i_1}^{[1]} \psi_{i_2}^{[2]} \cdots \psi_{i_N}^{[N]}.
\]</div>
<p>This product is actually already in the form of an MPS, with bond dimension 1. We simply need to take the two-dimensional vectors <span class="math notranslate nohighlight">\(\psi^{[i]}\)</span> and reshape them into rank-3 tensors with dimensions <span class="math notranslate nohighlight">\((1, 2, 1)\)</span>. We could easily add this to our MPS class (good exercise), but for now we will add a simplified version that creates a basis state, i.e., where each site is in a definite state, <span class="math notranslate nohighlight">\(\uparrow\)</span> or <span class="math notranslate nohighlight">\(\downarrow\)</span> (<span class="math notranslate nohighlight">\(0\)</span> or <span class="math notranslate nohighlight">\(1\)</span>).</p>
<div class="admonition-code-product-state admonition">
<p class="admonition-title">Code: Product State</p>
<p>Let’s add a method to the MPS class that creates a product state. We can specify the state as a list of <span class="math notranslate nohighlight">\(0\)</span>’s and <span class="math notranslate nohighlight">\(1\)</span>’s, where <span class="math notranslate nohighlight">\(0\)</span> corresponds to <span class="math notranslate nohighlight">\(\uparrow\)</span> and <span class="math notranslate nohighlight">\(1\)</span> to <span class="math notranslate nohighlight">\(\downarrow\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">## file: src/mps.py</span>

<span class="k">class</span> <span class="nc">MPS</span><span class="p">:</span>
    
    <span class="c1">## PREVIOUS CODE EXCLUDED ##</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">productState</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a product state MPS on L sites in a given basis state on each site.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        L : int</span>
<span class="sd">            Number of sites.</span>
<span class="sd">        state : list of ints</span>
<span class="sd">            List of basis states for each site. E.g. [0, 1, 0, 1] for a 4-site system.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;Basis states must be 0 or 1.&quot;</span>

            <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>

        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="summary">
<h2><span class="section-number">3.8. </span>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h2>
<p>This week we have introduced the problem we want to solve and presented Matrix Product State methods as a way to solve it. We have introduced the basic structure of the MPS, and shown how to convert a state vector into an MPS and back again. In the process we introduced tensor network diagrams and the numpy functions <code class="docutils literal notranslate"><span class="pre">tensordot</span></code>, <code class="docutils literal notranslate"><span class="pre">transpose</span></code>, and <code class="docutils literal notranslate"><span class="pre">reshape</span></code>, which will central to all the code we write in this course. It is important to understand these functions well, so I recommend playing about with these, and attempt the simple exercises in the Section <a class="reference internal" href="#tensordot"><span class="std std-ref">Numpy tensordot and transpose</span></a>.</p>
<div class="admonition-tests-mps-basics admonition">
<p class="admonition-title">Tests: MPS basics</p>
<p>It is also important that you test the MPS class and it’s methods that you have written. Write the following tests.</p>
<ol class="arabic simple">
<li><p>Create a random complex vector of length <span class="math notranslate nohighlight">\(2^N\)</span> (for <span class="math notranslate nohighlight">\(N&lt;10\)</span>). Normalise this vector then convert it to an MPS and back to a vector. Check that the original vector and the final vector are the same.</p></li>
<li><p>Use the ED code (import using <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">src.ed</span> <span class="pre">import</span> <span class="pre">*</span></code>) to compute the ground state of the Heisenberg model for <span class="math notranslate nohighlight">\(N&lt;10\)</span>. Convert this state to an MPS and back to a vector. Check that the original vector and the final vector are the same.</p></li>
<li><p>Create the product state <span class="math notranslate nohighlight">\(|0000\rangle\)</span> and convert this to a vector. Check that the vector is the same as the basis state <span class="math notranslate nohighlight">\(|0000\rangle\)</span>, it should have a 1 in the first element.</p></li>
<li><p>Create a basis state of your choice and convert to a vector. Check that the vector is the same as the basis state. The vector should have all zero elements except for a 1 in the position corresponding to the basis state. The binary representation of the basis state is the index of the 1 in the vector. e.g. <span class="math notranslate nohighlight">\(|0101\rangle\)</span> should have a 1 in the 5th element of the vector.</p></li>
</ol>
<p>I would recommend adding a file <code class="docutils literal notranslate"><span class="pre">mps_basics.py</span></code> to your <code class="docutils literal notranslate"><span class="pre">test</span></code> directory and working through these exercises there. Using <span class="math notranslate nohighlight">\(N&lt;10\)</span> should make this quick on most laptops. Make sure to add the line <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">fix_pathing</span> <span class="pre">import</span> <span class="pre">root_dir</span></code>. You can then import your MPS class using <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">src.mps</span> <span class="pre">import</span> <span class="pre">MPS</span></code>.</p>
</div>
<p>Next week we will start by introducing a specific form of the MPS tensors called canonical form, which will allow us to perform more efficient calculations, and is important for correctly truncating our tensors. We will then implement the Time Evolving Block Decimation (TEBD) algorithm, which is a way to simulate the time evolution of a quantum system using MPS.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/week1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="problem.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2. </span>The Heisenberg Antiferromagnet</p>
      </div>
    </a>
    <a class="right-next"
       href="../week2/canonical.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Canonical Form and Truncation</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantum-states-of-many-spins">3.1. Quantum states of many spins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3.2. Matrix Product States</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor-network-diagrams">3.3. Tensor network diagrams</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#numpy-tensordot-and-transpose">3.4. Numpy tensordot and transpose</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mps-from-a-state-vector">3.5. MPS from a state vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mps-to-vector">3.6. MPS to vector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#product-states">3.7. Product states</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">3.8. Summary</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Adam Gammon-Smith
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>